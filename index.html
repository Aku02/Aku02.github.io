<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-163784922-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};
        //JS: "||" is OR function, push() is append()
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

gtag('config', 'UA-163784922-1');
    </script>
    <title>Akash </title>
    <meta name="author" content="Akash ">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/jpg" href="data/akash2.jpg">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Akash </name>
                        </p>

                        <p> Hello There! I'm an undergrad <a href="https://tce.edu/">@TCE</a> pursuing Mechanical Engineering.</p>

                        <p>I'm just another human in planet EARTH C-137. :) </p>

                        <p><a href="mailto:kaakash11c@gmail.com">Drop a message here!</a>!</p>

                        <p style="text-align:center">
                            <a href="mailto:kaakash11c@gmail.com">Email</a> &nbsp/&nbsp
                            <a href="data/cv-akash.pdf"
                               onclick="ga('send', 'event', 'Videos', 'play', 'Fall Campaign')">CV</a> &nbsp/&nbsp
                            <a href="https://www.kaggle.com/ak0210/"> kaggle </a> &nbsp/&nbsp
                            <a href="https://github.com/Aku02"> Github </a> &nbsp/&nbsp
                            <a href="https://scholar.google.com/citations?user=RyZLpyIAAAAJ&hl=en"> Google Scholar </a> &nbsp/&nbsp
                            <a href="https://www.linkedin.com/in/akash-k-737884192/"> LinkedIn </a>
                            

                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="data/akash2.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                                                         src="data/akash2.jpg" class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>




            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding-left:20px;padding-right:20px;padding-top:20px;width:25%;vertical-align:middle">
                        <heading>Research</heading>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="lh_image" style="opacity: 0;">
                                <video muted="" autoplay="" loop="" width="100%" height="100%">
                                    <source src="data/cos-eor/iiwa.gif" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src="data/cos-eor/iiwa.gif">
                        </div>
                    </td>

                    <td style="padding:20px;width:100%;vertical-align:top">
                        <a href="https://arxiv.org/abs/2207.01583">
                            <papertitle>Building skeletonized articulated models from casual videos</papertitle>
                        </a>
                        <br>
                        <strong>Manuscript in preparation</strong>
                        <br>
                        <!-- <em>ECCV, 2022</em> -->
                        <br>
                        <a href="https://arxiv.org/abs/2112.12761">arXiv</a> /
                        <a href="https://docs.google.com/presentation/d/e/2PACX-1vRBPKVI6uOB22zxdaau1E4KmFhPMeL5P_ZzBSoiUrsfOTTwdKzFV7dHpSikbpD2DMA45-5x23BI12ms/pub?start=false&loop=false&delayms=3000">code</a>
                        <br> Kinematic aware, Animatable and Class-agnostic 3D deformable objects from causual monocular videos without the use any priors or camera poses - <strong>A Template free approach</strong> <br>
                        <br> <strong>Keywords: NeRF , Nerual Blend Skinning , Camera pose optimisation</strong> <br>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="lh_image" style="opacity: 0;">
                                <video muted="" autoplay="" loop="" width="100%" height="100%">
                                    <source src="data/lyft/lyft.gif" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src="data/lyft/lyft.gif">
                        </div>
                    </td>

                    <td style="padding:20px;width:100%;vertical-align:top">
                        <a href="https://akash.github.io/housekeep">
                            <papertitle>Lyft L5 toolkit - <strong>Motion forcasting</strong> </strong></papertitle>
                        </a>
                        <br>
                        <em>Kaggle - Build motion prediction models for self-driving vehicles | 2021</em>
                        <br>
                        <!-- <a href="https://arxiv.org/abs/2205.10712">arXiv</a> / -->
                        <a href="https://docs.google.com/presentation/d/e/2PACX-1vSwqeuDqgy_TqODsvNGKlJ32XHan7UcPLeJa0X21imF1T3fk5rb_g8c2Xhe_yk4yePWjuvveijXyFed/pub?start=false&loop=false&delayms=1000&slide=id.p">Model Architecture</a> /
                        <a href="https://gitfront.io/r/user-7662064/yTzSmPmkkuYB/vectornet-working/">code</a> /
                        <!-- <a href="https://colab.research.google.com/drive/12LweZ0xlGlO_SP4-pz1wbb5tOlXHLZ5R?usp=sharing">colab</a> -->
                        <br>
                        Motion prediction with the help of rasterized set of images, CNN , LSTM encoder-decoder based model. 
                        <br>
                        <br>
                        Also, currenly exploring a Vectornet based approach skipping the whole razterization part and making the pipeline faster.
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="lh_image" style="opacity: 0;">
                                <video muted="" autoplay="" loop="" width="100%" height="100%">
                                    <source src="data/anno/nfl.gif" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src="data/anno/nfl.gif">
                        </div>
                    </td>

                    <td style="padding:20px;width:100%;vertical-align:top">
                        <a href="https://gitfront.io/r/user-7662064/1csDFNTX7w7M/FairMOT/">
                            <papertitle>Segment and label helmets in video footage</papertitle>
                        </a>
                        <br>
                        <em>Kaggle - NFL, 2021</em>
                        <br>
                        <!-- <a href="https://arxiv.org/abs/2010.06087">arXiv</a> / -->
                        <a href="https://docs.google.com/presentation/d/e/2PACX-1vTOKESkB1xbv3_IKvDgmN3UZiTgd5LOIM19-kxLes3fIt0titlB2MvVaf0E-qxCUChcBsMSLtXNrHhd/pub?start=true&loop=false&delayms=60000">results</a> /
                        <a href="https://gitfront.io/r/user-7662064/1csDFNTX7w7M/FairMOT/">code</a> /
                        <!-- <a href="https://akash.github.io/data/lyft/slides.pdf">slides</a> -->
                        <br>
                        <p> • Detector to find helmets, Image2Map (BEV) <br>
                            • Classifier to classify players into 2(H/V) teams and Registration of detected players on 2D map to provided tracking data. Later track detected <br>
                            bounding boxes and reassign players. <br> 
                            • Predict the 2022 College Men’s Basketball Tournament <br>
                            • Analyse the trend based on past 5 year’s data</p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="lh_image" style="opacity: 0;">
                                <video muted="" autoplay="" loop="" width="100%" height="100%">
                                    <source src="data/anno/annno.gif" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src="data/anno/annno.gif">
                        </div>
                    </td>

                    <td style="padding:20px;width:100%;vertical-align:top">
                        <a href="https://akash.github.io/projects/sam-textvqa.html">
                            <papertitle>Automated Annotation and Classification of Catheters in Chest X-Rays</papertitle>
                        </a>
                        <br>
                        <strong>Akash </strong>,
                        <a href="https://scholar.google.co.in/citations?user=_cpaQAgAAAAJ&hl=en">Saravana Perumaal Subramanian</a>,
                        <br>
                        <em>ICCCSP, 2022</em>
                        <br>
                        <a href="https://doi.org/10.1007/978-3-031-11633-9_12">paper</a> /
                        <!-- <a href="https://akash.github.io/projects/sam-textvqa.html">project page</a> / -->
                        <a href="https://www.kaggle.com/ak0210/datagen-chromagan">data</a> /
                        <!-- <a href="https://www.youtube.com/watch?v=uPZra6HfLd0">short talk</a> / -->
                        <!-- <a href="https://www.youtube.com/watch?v=rO89lcTvz2U">long talk</a> / -->
                        <!-- <a href="https://akash.github.io/data/sam-textvqa/slides.pdf">slides</a> -->
                        <br>
                        <p>Annotate and classify cathater position. Robust approach to get the endpoints of the cathaters even though the enpoints contribute to a less than 1% footprint of the whole image </p>

                    </td>
                </tr>


                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="lh_image" style="opacity: 0;">
                                <video muted="" autoplay="" loop="" width="100%" height="100%">
                                    <source src="data/anno/annno.gif" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src="data/anno/input_downtown.png">
                        </div>
                    </td>

                    <td style="padding:20px;width:100%;vertical-align:top">
                        <a href="https://akash.github.io/projects/sam-textvqa.html">
                            <papertitle>Google Deciemter Challenge</papertitle>
                        </a>
                        <em>Kaggle | Google, 2022</em>
                        <br>
                        <a href="https://gitfront.io/r/user-7662064/4ztCA49Ed8nB/google-decimeter-kaggle/">code</a> /
                        <!-- <a href="https://akash.github.io/projects/sam-textvqa.html">project page</a> / -->
                        <a href="https://docs.google.com/presentation/d/e/2PACX-1vQnTFFu59SjXbnNJzzFNSOzpah7jFZR589Evi2TBBZOxrW_AcdrI2_vvNM3W9Zj5zBmcMV4exb0caka/pub?start=true&loop=false&delayms=3000&slide=id.p">Architecture</a> 
                        <!-- <a href="https://www.youtube.com/watch?v=uPZra6HfLd0">short talk</a> / -->
                        <!-- <a href="https://www.youtube.com/watch?v=rO89lcTvz2U">long talk</a> / -->
                        <!-- <a href="https://akash.github.io/data/sam-textvqa/slides.pdf">slides</a> -->
                        <br>
                        <p> • Improve high precision GNSS positioning and navigation accuracy on smartphones <br>
                            • Process and clean the GNSS logs to compute location down to decimeter or even centimeter resolution placed 94/810  <br>
                            • Use of Kalman smoothening and constant velocity heading model to improve accuracy of GNSS data, more visualization in repo</p>

                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="lh_image" style="opacity: 0;">
                                <video muted="" autoplay="" loop="" width="100%" height="100%">
                                    <source src="data/anno/nvidia.gif" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src="data/anno/nvidia.gif">
                        </div>
                    </td>

                    <td style="padding:20px;width:100%;vertical-align:top">
                        <a href="https://drive.google.com/file/d/1cK6_svEmX9g9g918rskVBv53IqlNbfYz/view?usp=share_link">
                        <papertitle>Action Recognition and Tracking of People in Realtime</papertitle>
                        </a>
                        <br>
                        <a href="data/anno/NVIDIA_Inevitable.pdf">slides</a> 
                        <!-- <a href="https://akash.github.io/projects/sam-textvqa.html">project page</a> / -->
                        <!-- <a href="https://www.kaggle.com/ak0210/datagen-chromagan">data</a> / -->
                        <!-- <a href="https://www.youtube.com/watch?v=uPZra6HfLd0">short talk</a> / -->
                        <!-- <a href="https://www.youtube.com/watch?v=rO89lcTvz2U">long talk</a> / -->
                        <!-- <a href="https://akash.github.io/data/sam-textvqa/slides.pdf">slides</a> -->
                        <br>
                        <em>Winning Solutuion | NVIDIA - ACADEMIA CONNECT HACKATHON, 2021</em>
                        <br>
                                            <p>End2End detection, pose-estimation and tracking with ReID of crowded regions under various lighting conditions </p>
                        <br>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="lh_image" style="opacity: 0;">
                                <video muted="" autoplay="" loop="" width="100%" height="100%">
                                    <source src="data/anno/nvidia.gif" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src="data/anno/dolg.png">
                        </div>
                    </td>

                    <td style="padding:20px;width:100%;vertical-align:top">
                        <papertitle>Landmark Recognition | Google </papertitle>
                        <br>
                        <a href="https://gitfront.io/r/user-7662064/yq4Mt9L62suA/GLR-2021/">code</a> 
                        <!-- <a href="https://akash.github.io/projects/sam-textvqa.html">project page</a> / -->
                        <!-- <a href="https://www.kaggle.com/ak0210/datagen-chromagan">data</a> / -->
                        <!-- <a href="https://www.youtube.com/watch?v=uPZra6HfLd0">short talk</a> / -->
                        <!-- <a href="https://www.youtube.com/watch?v=rO89lcTvz2U">long talk</a> / -->
                        <!-- <a href="https://akash.github.io/data/sam-textvqa/slides.pdf">slides</a> -->
                        <br>
                        <em>ICCV 2022 Workshop Competition |  58/930</em>
                        <br>
                                            <p>
                                                • Use of Additive Angular Margin Loss (ArcFace), and other Bag-of-tricks from person re-identification
                                                <br>
                                                • Random Erasing, label smooth, triplet loss, IBN-extension, last stride=1
                                                <br>
                                                • Used DELF and DOLG based approches to find and extract features/ Similar stuff used here also for <a href="https://gitfront.io/r/user-7662064/VcNDApkcRkHC/whale/">Happy Dolphin comp</a> 
                                            </p>
                        <br>
                    </td>
                </tr> 

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="lh_image" style="opacity: 0;">
                                <video muted="" autoplay="" loop="" width="100%" height="100%">
                                    <source src="data/anno/nvidia.gif" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src="data/anno/mof.png">
                        </div>
                    </td>

                    <td style="padding:20px;width:100%;vertical-align:top">
                        <a href="https://doi.org/10.1007/978-981-15-8586-9_14">
                        <papertitle>Zero Energy Air-Cooler</papertitle>
                        </a>
                        <em><a href="https://www.editn.in/pages/view/tamil-nadu-student-innovators-programme"> TNSI - 2022</a></em>
                        <br>
                                            <p>• Device fabrication and characterization of MOF as advanced moisture sorbents for energy-efficient high temperature cooling 
                                                <br>
                                                • Performed XRD and Thermogravimetric Analysis to determine the structure of MOF and water update respectively.
                                            </p>
                        <br>
                    </td>
                </tr>             
                

                


                </tbody>
            </table>



<!--            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">-->
<!--                <tbody>-->
<!--                <tr>-->
<!--                    <td style="padding-left:20px;padding-right:20px;padding-top:20px;width:25%;vertical-align:middle">-->
<!--                        <heading>Research</heading>-->
<!--                    </td>-->
<!--                </tr>-->

<!--                <tr>-->
<!--                    <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--                        <div class="one">-->
<!--                            <div class="two" id="lh_image" style="opacity: 0;">-->
<!--                                <video muted="" autoplay="" loop="" width="100%" height="100%">-->
<!--                                    <source src="data/lyft/teaser.gif" type="video/mp4">-->
<!--                                    Your browser does not support the video tag.-->
<!--                                </video>-->
<!--                            </div>-->
<!--                            <img src="data/lyft/teaser.gif">-->
<!--                        </div>-->
<!--                    </td>-->

<!--                    <td style="padding:20px;width:100%;vertical-align:top">-->
<!--                        <a href="https://akash.github.io/projects/concat-vqa.html">-->
<!--                            <papertitle>Contrast and Classify: Training Robust VQA Models</papertitle>-->
<!--                        </a>-->
<!--                        <br>-->
<!--                        <strong>Akash </strong>,-->
<!--                        <a href="https://amoudgl.github.io/">Abhinav Moudgil</a>,-->
<!--                        <a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>,-->
<!--                        <a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>,-->
<!--                        <a href="https://dexter1691.github.io/">Harsh Agrawal</a>-->
<!--                        <br>-->
<!--                        <em>International Conference on Computer Vision (ICCV), 2021</em>-->
<!--                        <br>-->
<!--                        <em> Self-Supervised Learning Workshop at NeurIPS, 2020</em>-->
<!--                        <br>-->
<!--                        <a href="https://arxiv.org/abs/2010.06087">arXiv</a> /-->
<!--                        <a href="https://akash.github.io/projects/concat-vqa.html">project page</a> /-->
<!--                        <a href="https://github.com/akash/concat-vqa">code</a> /-->
<!--                        <a href="https://akash.github.io/data/lyft/slides.pdf">slides</a>-->
<!--                        <br>-->
<!--                        <p>We propose a training scheme which steers VQA models towards answering paraphrased questions consistently, and we ended up beating previous baselines by an absolute 5.8% on consistency metrics without any performance drop!</p>-->
<!--                    </td>-->
<!--                </tr>-->

<!--                <tr>-->
<!--                    <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--                        <div class="one">-->
<!--                            <div class="two" id="lh_image" style="opacity: 0;">-->
<!--                                <video muted="" autoplay="" loop="" width="100%" height="100%">-->
<!--                                    <source src="data/sam-textvqa/textvqa-workshop.gif" type="video/mp4">-->
<!--                                    Your browser does not support the video tag.-->
<!--                                </video>-->
<!--                            </div>-->
<!--                            <img src="data/sam-textvqa/textvqa-workshop.gif">-->
<!--                        </div>-->
<!--                    </td>-->

<!--                    <td style="padding:20px;width:100%;vertical-align:top">-->
<!--                        <a href="https://akash.github.io/projects/sam-textvqa.html">-->
<!--                            <papertitle>Spatially Aware Multimodal Transformers for TextVQA</papertitle>-->
<!--                        </a>-->
<!--                        <br>-->
<!--                        <strong>Akash </strong>,-->
<!--                        <a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>,-->
<!--                        <a href="https://panderson.me/">Peter Anderson</a>,-->
<!--                        <a href="https://www.cc.gatech.edu/~jlu347/">Jiasen Lu</a>,-->
<!--                        <a href="https://www.alexander-schwing.de/">Alexander Schwing</a>,-->
<!--                        <a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>,-->
<!--                        <a href="https://dexter1691.github.io/">Harsh Agrawal</a>-->
<!--                        <br>-->
<!--                        <em>European Conference on Computer Vision (ECCV), 2020</em>-->
<!--                        <br>-->
<!--                        <em>VQA Workshop at CVPR, 2020</em>-->
<!--                        <br>-->
<!--                        <a href="https://arxiv.org/abs/2007.12146">arXiv</a> /-->
<!--                        <a href="https://akash.github.io/projects/sam-textvqa.html">project page</a> /-->
<!--                        <a href="https://github.com/akash/sam-textvqa">code</a> /-->
<!--                        <a href="https://www.youtube.com/watch?v=uPZra6HfLd0">short talk</a> /-->
<!--                        <a href="https://www.youtube.com/watch?v=rO89lcTvz2U">long talk</a> /-->
<!--                        <a href="https://akash.github.io/data/sam-textvqa/slides.pdf">slides</a>-->
<!--                        <br>-->
<!--                        <p>We built a self-attention module to reason over spatial graphs in images. We ended up with an absolute performance improvement of more than 4% on two TextVQA bechmarks! </p>-->

<!--                    </td>-->
<!--                </tr>-->

<!--                <tr>-->
<!--                    <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--                        <div class="one">-->
<!--                            <div class="two" id="lh_image" style="opacity: 0;">-->
<!--                                <video muted="" autoplay="" loop="" width="100%" height="100%">-->
<!--                                    <source src="data/lyft/teaser.gif" type="video/mp4">-->
<!--                                    Your browser does not support the video tag.-->
<!--                                </video>-->
<!--                            </div>-->
<!--                            <img src="data/visdial-on-demand/chi_ea_system.png">-->
<!--                        </div>-->
<!--                    </td>-->

<!--                    <td style="padding:20px;width:100%;vertical-align:top">-->
<!--                        <a href="https://dl.acm.org/doi/10.1145/3411763.3451810">-->
<!--                        <papertitle>Automated Video Description for Blind and Low Vision Users</papertitle>-->
<!--                        </a>-->
<!--                        <br>-->
<!--                        Aditya Bodi, Pooyan Fazli, Shasta Ihorn, Yue-Ting Siu, Andrew T Scott, Lothar Narins,-->
<!--                        <br>-->
<!--                        <strong>Akash </strong>, Abhishek Das, Ilmi Yoon-->
<!--                        <br>-->
<!--                        <em>CHI Extended Abstracts 2021</em>-->
<!--                        <br>-->
<!--                        <a href="https://dl.acm.org/doi/10.1145/3411763.3451810">paper</a>-->
<!--                                                <p>We built a system to automatically generate descriptions for videos and answer blind and low vision users’ queries on the videos!</p>-->
<!--                        <br>-->
<!--                    </td>-->
<!--                </tr>-->


<!--                </tbody>-->
<!--            </table>-->




            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Projects</heading>
                        <p class="content">
                        <ul>
                            <li><b><i>MMDet Ultimate Detection and Segmentation Toolkit:</i></b> I experimented with MMDet Pipeline for medical image segmentation <a
                                        href="https://gitfront.io/r/user-7662064/x8w6pUfmQLvq/MMdet-tool/">code</a> based on competition hosted <a
                                        href="https://www.kaggle.com/competitions/sartorius-cell-instance-segmentation">here</a>,
                                placed 119/1505 participants
                            </li>
                            <li><b><i>G2Net Gravitational Wave Detection - European Gravitational Observatory:</i></b> Find gravitational wave signals from binary black hole collisions Used FFT and 1D CNN to detect the gravitational waves. 
                                <br> Placed 33/1219 teams</li>
                            <li><b><i>March Machine Learning Mania 2022 - Men’s:</i></b> Predict the 2022 College Men's Basketball Tournament (<a
                                        href="https://www.kaggle.com/competitions/mens-march-mania-2022">kaggle competition</a>, <strong>placed 14/930 participants</strong>, also here is the visulalization tool for bracket builing                    
                                        <a href="https://github.com/Aku02/NCAA_BracketBuilder">NCAA_BracketBuilder</a>
                            </li>
                            <li><b><i>Crypto- Market prediction based on anonymised features (<a
                                    href="https://www.kaggle.com/competitions/ubiquant-market-prediction">Ubiquant Market Prediction</a></i></b> I
                                Used <a href="https://arxiv.org/abs/1908.07442">Tabnet</a> based model to place 99/2893 participants.
                            </li>
                            
                        </ul>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="lh_image" style="opacity: 0;">
                                <video muted="" autoplay="" loop="" width="100%" height="100%">
                                    <source src="data/anno/nvidia.gif" type="video/mp4">
                                    Your browser does not support the video tag.
                                </video>
                            </div>
                            <img src="data/anno/yukta.jpeg">
                        </div>
                    </td>

                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Fun</heading>
                        <p class="content">
                        <ul>
                            <li> Checkout our go-karting team <a href="https://www.yuktaracing.com/">#lifeinthefastlane</a> webpage, </li>
                        </ul>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            I borrowed this template from Jon Barron's<a
                                href="https://github.com/jonbarron/jonbarron_website"> website</a>.
                            <br>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
        </td>
    </tr>
</table>
</body>

</html>
